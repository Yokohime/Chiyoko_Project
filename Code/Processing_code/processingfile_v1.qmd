---
title: "cleaning script"
author: "Chiyoko Onouye"
date: "2023-02-15"
output: html_document
---


# Processing script (data cleaning)


# Setup

Load needed packages. make sure they are installed.

```{r}
require(dplyr) #for data processing/cleaning
require(tidyr) #for data processing/cleaning
require(skimr) #for nice visualization of data 
```


# Data loading

Start R in the same directory that this script resides in `project_root/Code/Processing_code`.  If you need to check your working directory, use `getwd()`.


```{r}
# path to data
# note the use of relative and not absolute paths

data_location <- "../../Data/Raw_data/penguins_raw_dirty.csv"
data_path <- "../../Data/Raw_data/"
```

### Load data

I am using `check.names=F` because these names have spaces and parentheses and I want to preserve the original names.

```{r}
rawdata <- read.csv(data_location, check.names=FALSE)
```


# Check data


```{r}
dictionary <- read.csv(paste(data_path, "datadictionary.csv", sep=""))
print(dictionary)
```


### There are several ways of looking at the data



```{r}
dplyr::glimpse(rawdata)
summary(rawdata)
head(rawdata)
skimr::skim(rawdata)
```

See all the data by just typing `rawdata` at the R console.

Note that the names in the penguin dataset have spaces and () which are usable, but force us to quote the character strings.

```{r eval=F}
# names(rawdata) <- c("study", "sampleN", "species", "region", "island", "stage", "id", ... )
```

# Cleaning

Inspecting the data, we find some problems that need addressing. 

###  Species names

First, we know that this is a dataset for three species of penguin, but we notice that there are 9 unique species.

```{r}
#check skimr or 
unique(rawdata$Species)
```

There are some typos so I saved rawdata as d1, and modify d1 so we can compare versions. 

```{r}
d1 <- rawdata
```

Use the techniques we learned in class to fix these errors. For example, we can find the mispelled entry, and replace the whole thing:

```{r}
ii <- grep("PengTin", d1$Species)
d1$Species[ii] <- "Adelie Penguin (Pygoscelis adeliae)"

unique(d1$Species)   # look at partially fixed data again  
```

Fix all of the errors. 
```{r}
jj <- grep("AdeKie Penguin", d1$Species)
d1$Species[jj] <- "Adelie Penguin (Pygoscelis adeliae)"

hh <- grep("Adelie Pengufn ", d1$Species)
d1$Species[hh] <- "Adelie Penguin (Pygoscelis adeliae)"

kk <- grep("Adelie PeOguin", d1$Species)
d1$Species[kk] <- "Adelie Penguin (Pygoscelis adeliae)"

pp <- grep("AdelieMPenguin", d1$Species)
d1$Species[pp] <- "Adelie Penguin (Pygoscelis adeliae)"

oo <- grep("Ventoo penguin", d1$Species)
d1$Species[oo] <- "Gentoo penguin (Pygoscelis papua)"
```


Also, letʻs shorten Species just keeping the three common names "Adelie", "Gentoo", and "Chinstrap" and delete the rest of the Species character string. 
```{r}
#Changing (Pygoscelis adeliae)-->Adelie
aa <- grep("(Pygoscelis adeliae)", d1$Species)
d1$Species[aa] <- "Adelie "
#Changing (Pygoscelis papua)-->Gentoo
ss <- grep("(Pygoscelis papua)", d1$Species)
d1$Species[ss] <- "Gentoo"
#Changing (Pygoscelis antarctica)-->Chinstrap
dd <- grep("(Pygoscelis antarctica)", d1$Species)
d1$Species[dd] <- "Chinstrap"
#Checking to make sure the Species names were all shortened correctly.
unique(d1$Species)


```


### Continuous data

There is an entry for `Culmen Length (mm)` which says "missing" instead of a number or NA. 
This "missing" entry also turned all culmen length entries into characters instead of numeric.
That conversion to character also means that our summary function isn't very meaningful.

So let's fix that first.

```{r}
cl <- d1$`Culmen Length (mm)` 
                              # Letʻs make a temporary variable `cl` and save it 
                              # back to d1$`Culmen Length (mm)` when weʻre done. 

cl[ cl == "missing" ] <- NA  # find cl=="missing and replace "missing" with NA
cl <- as.numeric(cl)  # coerce to numeric
d1$`Culmen Length (mm)` <- cl
```

Look at partially fixed data again

```{r}
skimr::skim(d1)
hist(d1$`Culmen Length (mm)`)
```

Letʻs also do a bivariate plot with mass
```{r}
plot(d1$`Body Mass (g)`, d1$`Culmen Length (mm)`)
```


Now we see that there are three penguins with really really long culmens (300+mm) that could be typos. If we don't know, we might need to remove these penguins. But let's suppose that we somehow know that this is because of a misplaced decimal point (for example if we could verify with field records), and letʻs fix this:

```{r}
d2 <- d1 
cl[ cl > 300 ] 
```

Notice that NAʻs will match the condition `cl>300`, because we donʻt really know, so R returns it to be conservative. We donʻt want NAs, so letʻs exclude them with 
!is.na()  where the ! is "not" or the opposite of is.na. 

```{r}
cl[ !is.na(cl) & cl>300 ]
```

Now replace with the same divided by 10:

```{r}
cl[ !is.na(cl) & cl>300 ] <- cl[ !is.na(cl) & cl>300 ]/10  

d2$`Culmen Length (mm)` <- cl
```

Culmen length values seem ok now

```{r}
skimr::skim(d2)
hist(d2$`Culmen Length (mm)`)

plot(d2$`Body Mass (g)`, d2$`Culmen Length (mm)`)
```


### Now let's look at body mass.

There are penguins with body mass of <100g when the others are over 3000. 
Perhaps these are new chicks? But they are supposed to be adults. Letʻs remove them.

```{r}
hist(d2$`Body Mass (g)`)
```

Mass is the main size variable, so we will probably need to remove the individuals with missing masses in order to  be able to analyze the data. 


```{r}
d3 <- d2
mm <- d3$`Body Mass (g)`

mm[ mm < 100 ] <- NA       # replace tiny masses with NA
nas <- which( is.na(mm) )  # find which rows have NA for mass

d3 <- d3[ -nas, ]   # drop the penguins (rows) with missing masses

skimr::skim(d3)
hist(d3$`Body Mass (g)`)

plot(d3$`Body Mass (g)`, d3$`Culmen Length (mm)`)
```


### Factors

We also want to have Species, Sex, and Island coded as a categorical/factor variable:

```{r}
d3$Species <- as.factor(d3$Species)
d3$Sex <- as.factor(d3$Sex)
d3$Island <- as.factor(d3$Island)  
skimr::skim(d3)
```

# Bivariate Plots

Make bivariate plots for any remaining continous data to ensure there are no further errors. It is a good check on the distribution of the data as well. 
```{r}
#Checking body mass vs culmen depth
plot(d3$`Body Mass (g)`, d3$`Culmen depth (mm)`)
#Checking body mass vs flipper length
plot(d3$`Body Mass (g)`, d3$`Flipper Length (mm)`)
#Checking Culmen length vs culmen depth
plot(d3$`Culmen Length (mm)`, d3$'Culmen depth (mm)')
#Checking Culmen length vs flipper length
plot(d3$`Culmen Length (mm)`, d3$'Flipper length (mm)')

```

Make histograms or densities of at least mass by discrete category, to check for any potential category errors, extra categories, etc.  
```{r}
hist(d3$`Culmen Length (mm)`)
hist(d3$`Culmen Depth (mm)`)
plot(d3$Species)
plot(d3$Sex )
plot(d3$Island)

```



# Finalize your cleaned dataset. 

Drop any variables (columns) that you wonʻt analyze.  If you have extra levels after dropping some values, you may want to relevel your factors (this may or may not happen). 

To specify new levels or orders of levels:

```{r eval=F}
#saving data as d4 incase we make a mistake
d4 <- d3
#selecting all the columns we did not use and deleting them from the dataframe
d5 = select(d4, -1:-2, -6:-9, -15:-17)
#double checking that all the columns we did not use were deleted and that all the columns we did use are still here
skimr::skim(d5)
```

# Save data

All done, data is clean now. 
Let's assign at the end to some final variable
makes it easier to add steps above

```{r}
processeddata <- d5     
```

Finally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files, as well as a copy as .csv

RDS/Rdata preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. If you do CSV, you might want to write down somewhere what each variable is (i.e. a data dictionary).

Location to save file:

```{r}
save_data_location <- "../../Data/Processed_data/processeddata.rds"
saveRDS(processeddata, file = save_data_location)

save_data_location_csv <- "../../Data/Processed_data/processeddata.csv"
write.csv(processeddata, file = save_data_location_csv, row.names=FALSE)
```


# Notes 

-  Anything you don't want loaded into the Quarto file but 
keep in the R file, just give it its own label and then just leave that label out of the Quarto file. For example, you may try excluding some of the excessive comments. 

-  Dealing with NA or "bad" data:
Removing anyone who had "faulty" or missing data is one approach, but it's often not the best. Based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep individuals with some missing information)

-  Saving data as RDS:
I suggest you save your processed and cleaned data as RDS or RDA/Rdata files.  This preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. 

-  If you do CSV, you must to write down somewhere what each variable is (i.e. in a data dictionary).

-  See here for some suggestions on how to store your processed data:
<http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata>
